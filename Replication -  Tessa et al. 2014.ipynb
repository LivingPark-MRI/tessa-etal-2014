{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Original paper:** [*Tessa C, Lucetti C, Giannelli M, Diciotti S, Poletti M, Danti S, Baldacci F, Vignali C, Bonuccelli U, Mascalchi M, Toschi N. Progression of brain atrophy in the early stages of Parkinson's disease: a longitudinal tensor-based morphometry study in de novo patients without cognitive impairment. Hum Brain Mapp. 2014 Aug;35(8):3932-44. doi: 10.1002/hbm.22449. Epub 2014 Jan 22. PMID: 24453162; PMCID: PMC6868950.*](https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.22449)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Cohort quote from the paper:** \"*Overall, 22 patients (4 women and 18 men, mean age 61.5 ± 8.8) and 17 control subjects (8 women and 9 men, mean age 59.1 ± 8.5 years) completed the study and underwent a second MRI examination. The mean (± standard deviation) follow-up time for patients and controls was 2.8 ± 0.6 (range 2–4) years and 3.9 ± 2.2 (range 2–7) years, respectively. Differences for age between PD patients and control subjects were not significant (P = 0.48, MannWhitney U-test)*\"\n",
    "\n",
    "\n",
    "* Demographics for the PD patients (table taken from the paper):\n",
    "<img src=\"./images/original-cohort.png\" alt= “” width=\"30%\" height=\"30%\">\n",
    "\n",
    "\n",
    "* At the baseline evaluation \"*No difference in local volume between patients and control subjects was revealed*\".\n",
    "\n",
    "\n",
    "* A (very) brief summary of the main results of the logtitudinal evaluation is:\n",
    "\n",
    "\n",
    "  * Control subjects: Baseline versus follow-up\n",
    "    * Control subjects experienced atrophy in several white matter and grey matter regions (Fig. 1a), and cerebrospinal fluid enlargement. There were atrophy clusters involved mainly in white matter, and were more widespread in the frontal lobe.\n",
    "    \n",
    "    \n",
    "  * PD patients: Baseline versus follow-up\n",
    "    * PD patients showed clusters of reduced white and grey matter volume. These were more evident in the white matter, specially the frontal lobe (Fig. 1b), and showed cerebrospinal fluid enlargement. Grey matter involvement was more widespread than in the control subjects.\n",
    "    <img src=\"./images/original-fig1.png\" alt= “” width=\"50%\" height=\"50%\">\n",
    "    \n",
    "  * PD patients versus control subjects\n",
    "    * \"*PD patients developed bilateral clusters of increased atrophy*\" (Fig. 2).\n",
    "    <img src=\"./images/original-fig2.png\" alt= “” width=\"50%\" height=\"50%\">\n",
    "    \n",
    "    \n",
    "  * Correlation analyses\n",
    "    * \"*In PD patients, no significant correlation between warprates and motor or neuropsychological test scores or their average changes per year between baseline and follow-up were identified*\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook was run on 2023-03-29 00:39:44 UTC +0000\n",
      "['COR', 'Coronal', 'Cal Head 24', 'Transverse', 'tra_T1_MPRAGE', 'TRA']\n",
      "['AX', 'Ax', 'axial', 'Phantom', 'T2']\n",
      "{'Screening': 'SC', 'Baseline': 'BL', 'Month 6': 'V02', 'Month 12': 'V04', 'Month 24': 'V06', 'Month 36': 'V08', 'Month 48': 'V10', 'Symptomatic Therapy': 'ST', 'Unscheduled Visit 01': 'U01', 'Unscheduled Visit 02': 'U02', 'Premature Withdrawal': 'PW'}\n",
      "Saved in MRI_info.csv\n"
     ]
    }
   ],
   "source": [
    "# Importing the modules we need\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import statistics\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "import livingpark_utils\n",
    "from livingpark_utils import download\n",
    "from livingpark_utils import clinical\n",
    "from livingpark_utils.scripts import run\n",
    "from livingpark_utils.scripts import mri_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook was run on 2023-03-29 00:39:44 UTC +0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>\n",
       "    code_show = true;\n",
       "    function code_toggle() {\n",
       "        if (code_show) {\n",
       "            $(\"div.input\").hide();\n",
       "        } else {\n",
       "            $(\"div.input\").show();\n",
       "        }\n",
       "        code_show = !code_show\n",
       "    }\n",
       "    $(document).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\">\n",
       "    <input type=\"submit\" value=\"Click here to toggle on/off the Python code.\">\n",
       "</form>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notebook data initialization\n",
    "inputs_dir = os.path.join(os.getcwd(), \"inputs/study_files\")\n",
    "outputs_dir = os.path.join(os.getcwd(), \"outputs\")\n",
    "data_dir = os.path.join(os.getcwd(), \"data\")\n",
    "\n",
    "utils = livingpark_utils.LivingParkUtils()\n",
    "downloader = download.ppmi.Downloader(utils.study_files_dir)\n",
    "#random_seed = 1\n",
    "utils.notebook_init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPMI Cohort Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download skipped: No missing files!\n"
     ]
    }
   ],
   "source": [
    "# PPMI study data files to reconstruct cohort and demographics table\n",
    "\n",
    "required_files = [\n",
    "    \"Demographics.csv\",                                   # Sex\n",
    "    \"Age_at_visit.csv\",                                   # Age\n",
    "    \"Montreal_Cognitive_Assessment__MoCA_.csv\",           # MMSE\n",
    "    \"PD_Diagnosis_History.csv\",                           # Disease duration\n",
    "    \"Cognitive_Categorization.csv\",                       # MCI diagnosis\n",
    "    \"Participant_Status.csv\",                             # Parkinson's vs healthy diagnosis\n",
    "    \"Primary_Clinical_Diagnosis.csv\",                     # Subjects with no PD nor other neurological disorder\n",
    "    \"Geriatric_Depression_Scale__Short_Version_.csv\",     # GDSS - depression screening\n",
    "    \"Family_History.csv\",                                 # PD familial history\n",
    "    \"General_Physical_Exam.csv\",                          # Cardio-vascular dysfunction (exclusion)\n",
    "    \"Magnetic_Resonance_Imaging__MRI_.csv\",               # Baseline & ~24 month follow-up T1w images\n",
    "    #\"MDS_UPDRS_Part_II__Patient_Questionnaire.csv\",      # UPDRS II\n",
    "    \"MDS-UPDRS_Part_III.csv\",                             # UPDRS III, and Hoehn and Yahr scores\n",
    "    \"Medical_Conditions_Log.csv\"                          # Depression diagnosis (and other neuro/psych conditions)\n",
    "]\n",
    "\n",
    "utils.get_study_files(required_files, default=downloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Reading in all the demographic info files for the relevant variables\n",
    "\n",
    "# Age\n",
    "age_df = pd.read_csv(os.path.join(inputs_dir, \"Age_at_visit.csv\"), usecols=[\"PATNO\", \"EVENT_ID\", \"AGE_AT_VISIT\"])\n",
    "\n",
    "\n",
    "# Sex\n",
    "sex_df = pd.read_csv(os.path.join(inputs_dir,\"Demographics.csv\"), usecols=[\"PATNO\", \"SEX\"])\n",
    "\n",
    "\n",
    "# Diagnosis\n",
    "diagnosis_df = pd.read_csv(os.path.join(inputs_dir, \"Primary_Clinical_Diagnosis.csv\"), usecols=[\"PATNO\", \"EVENT_ID\", \"PRIMDIAG\"])\n",
    "\n",
    "\n",
    "# Disease duration\n",
    "disease_duration_df = pd.read_csv(os.path.join(inputs_dir,\"PD_Diagnosis_History.csv\"), usecols=[\"PATNO\", \"EVENT_ID\", \"PDDXDT\"])\n",
    "disease_duration_df = disease_duration_df.drop([\"EVENT_ID\"], axis=1) \n",
    "\n",
    "\n",
    "# Cognitive categorization (MCI/Dementia/Healthy)\n",
    "cog_cat_df = pd.read_csv(os.path.join(inputs_dir, \"Cognitive_Categorization.csv\"), usecols=[\"PATNO\", \"EVENT_ID\", \"COGSTATE\"])\n",
    "\n",
    "\n",
    "# UPDRS3 and HY\n",
    "updrs3_df = pd.read_csv(os.path.join(inputs_dir,\"MDS-UPDRS_Part_III.csv\"), usecols=[\"PATNO\", \"EVENT_ID\", \"NP3TOT\", \"NHY\"])\n",
    "\n",
    "\n",
    "# Medical condition (Depression)\n",
    "med_cond_df = pd.read_csv(os.path.join(inputs_dir, \"Medical_Conditions_Log.csv\"), usecols=[\"PATNO\", \"EVENT_ID\", \"MHCAT\"]).groupby(['PATNO', 'EVENT_ID'])[['MHCAT']].aggregate(lambda x: tuple(set(x))) # aggregate all codes in a tuple\n",
    "dep = []\n",
    "for x in med_cond_df['MHCAT']:\n",
    "    if 115 in x: #115 = depression\n",
    "        dep.append(1)\n",
    "    else:\n",
    "        dep.append(0)     \n",
    "new_med = med_cond_df\n",
    "new_med['Depression'] = dep\n",
    "new_med = new_med.reset_index()\n",
    "new_med = new_med.drop([\"EVENT_ID\", \"MHCAT\"], axis=1) \n",
    "\n",
    "\n",
    "# MoCA --> MMSE\n",
    "moca_df = pd.read_csv(os.path.join(inputs_dir,\"Montreal_Cognitive_Assessment__MoCA_.csv\"), usecols=[\"PATNO\", \"EVENT_ID\", \"MCATOT\"])\n",
    "moca_df[\"MMSETOT\"] = moca_df[\"MCATOT\"].apply(clinical.moca2mmse)\n",
    "\n",
    "\n",
    "# Parkinson's (COHORT=1) vs healthy control (COHORT=2)\n",
    "part_stat_df = pd.read_csv(os.path.join(inputs_dir, \"Participant_Status.csv\"), usecols=[\"PATNO\", \"COHORT\"])\n",
    "\n",
    "\n",
    "# GDSS\n",
    "gdsshort_df = pd.read_csv(os.path.join(inputs_dir,\"Geriatric_Depression_Scale__Short_Version_.csv\"))\n",
    "gdsshort_df = gdsshort_df.drop([\"REC_ID\",\"PAG_NAME\", \"INFODT\",\"ORIG_ENTRY\",\"LAST_UPDATE\"], axis=1)\n",
    "gds = gdsshort_df.iloc[:, 2:] # Calculate GDS score for each patient\n",
    "gds = gds.agg(['sum'], axis=\"columns\").rename(columns={\"sum\": \"GDSTOT\"})\n",
    "gdsshort_df = pd.concat([gdsshort_df[['PATNO', 'EVENT_ID']], gds], axis=1) #Add gds score to df\n",
    "\n",
    "\n",
    "# Physical Examination (For now just need PESEQ=6 for cardiovascular...Might need neurological too?)\n",
    "physical_df = pd.read_csv(os.path.join(inputs_dir, \"General_Physical_Exam.csv\"), usecols=[\"PATNO\", \"PESEQ\", \"ABNORM\"])\n",
    "physical_df_mod = physical_df.loc[(physical_df['PESEQ'] == 6)]\n",
    "physical_df_mod = physical_df_mod.drop('PESEQ', axis=1)\n",
    "\n",
    "# MRI availability\n",
    "run.mri_metadata()\n",
    "mri_df = pd.read_csv(os.path.join(inputs_dir,\"MRI_info.csv\"))\n",
    "mri_df[\"EVENT_ID\"] = mri_df[\"Visit code\"]\n",
    "mri_df[\"PATNO\"] = mri_df[\"Subject ID\"]\n",
    "mri_df[\"Sex\"] = mri_df[\"Sex\"].map({\"F\": 0, \"M\": 1})\n",
    "mri_df = mri_df.drop([\"Subject ID\", \"Visit code\", \"Visit\", \"Age\", \"Sex\", \"Description\", \"Imaging Protocol\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging all of the relevant study file variables into one big dataframe\n",
    "\n",
    "result = pd.merge(age_df, sex_df, on=[\"PATNO\"], how=\"outer\")\n",
    "result = pd.merge(result, part_stat_df, on=[\"PATNO\"], how=\"outer\")\n",
    "result = pd.merge(result, diagnosis_df, on=[\"PATNO\", \"EVENT_ID\"], how=\"outer\")\n",
    "result = pd.merge(result, cog_cat_df, on=[\"PATNO\", \"EVENT_ID\"], how=\"outer\")\n",
    "result = pd.merge(result, updrs3_df, on=[\"PATNO\", \"EVENT_ID\"], how=\"outer\")\n",
    "result = pd.merge(result, moca_df, on=[\"PATNO\", \"EVENT_ID\"], how=\"outer\")\n",
    "result = pd.merge(result, gdsshort_df, on=[\"PATNO\", \"EVENT_ID\"], how=\"outer\")\n",
    "result = pd.merge(result, physical_df_mod, on=[\"PATNO\"], how=\"outer\")\n",
    "result = pd.merge(result, new_med, on=[\"PATNO\"], how=\"outer\") \n",
    "result = pd.merge(result, disease_duration_df, on=[\"PATNO\"], how=\"outer\")\n",
    "result = pd.merge(result, mri_df, on=[\"PATNO\", \"EVENT_ID\"], how=\"outer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cohort Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now attempt to reconstruct a cohort which is as similar to the original study as possible using the PPMI data.\n",
    "\n",
    "* ### Inclusion/Exclusion criteria I will use to replicate this study:\n",
    "\n",
    "\n",
    "  * Baseline and ~36 month follow-up T1-weighted MRIs available and usable for TBM. (MRI_info.csv: **Study Date**)\n",
    "  \n",
    "  \n",
    "  * Disease duration ~1 year at baseline (PD_Diagnosis_History.csv: **PDDXDT**).\n",
    "  \n",
    "  \n",
    "  * No MCI or dementia (Cognitive_Categorization.csv: **COGSTATE** != 3 for dementia, 2 for MCI)\n",
    "  \n",
    "  \n",
    "  * No depression (Medical_Conditions_Log.csv: **MHCAT** != 115 --> **Depression** != 1 in aggregation )\n",
    "  \n",
    "  \n",
    "  * No cardio-vascular autonomic dysfunction (General_Physical_Exam.csv: **PESAQ** == 6 && **ABNORM** == 0 --> **ABNORM** != 1 in aggregation)\n",
    "  \n",
    "  \n",
    "  * Subjects: 4 PD women and 18 PD men (Participant_Status.csv: **COHORT**==1 PD)\n",
    "  * Controls: 8 HC women and 9 HC men (Participant_Status.csv: **COHORT**==2 HC)\n",
    "  * Demographics.csv: **SEX**==1 Male, **SEX**==0 Female\n",
    "  \n",
    "  \n",
    "  * Controls: a normal neurological examination (Unsure: Primary_Clinical_Diagnosis.csv: **PRIMDIAG==17**, Or Neurological_exam.csv battery, or just Participant_Status.csv: **COHORT**==2?), and no relatives with PD (*See the notes below on how this differs from the original study*).\n",
    "  \n",
    "* ### Replication Limitations, and other points to consider\n",
    "\n",
    "\n",
    "  * For the control subjects, the original study states that they must have \"No history of familial or personal neurological diseases\". I can't find this detailed familial data in PPMI, the existing familial data is only with regard to PD.\n",
    "  \n",
    "  \n",
    "  * We are using the PPMI's cognitive state diagnosis for MCI instead of the original paper's battery of standardized neuropsychological tests.\n",
    "  \n",
    "  \n",
    "  * While it's not an inclusion/exclusion criterion, the paper states that  \"At follow-up examination, all patients were receiving L-dopa\". It makes no mention of L-dopa at baseline.\n",
    "  \n",
    "  * There are not enough female healthy controls in PPMI that meet our criteria, so we are using 6 female controls instead of 8, and using 11 men instead of 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scans in PD cohort: 44\n"
     ]
    }
   ],
   "source": [
    "#PD Subjects query\n",
    "\n",
    "# ~36 month followup, range 24-48 months within ~1yr of diagnoses (needs EVENT_ID = BL)\n",
    "visit2month = {\"V06\": 24, \"V10\": 48} # Visits with MRI scans\n",
    "\n",
    "#Initial filtering for inclusion/exclusion criteria\n",
    "PD_query = result.loc[(result['ABNORM'] == 0.0) &\n",
    "           (result['COGSTATE'] != 2.0) & \n",
    "           (result['COGSTATE'] != 3.0) &\n",
    "           (result['Depression'] != 1.0) &\n",
    "           (result['Study Date'].notnull()) &\n",
    "           (result['COHORT'] == 1.0)] #Need PRIMDIAG == 1, but doesn't seem necessary upon inspecting 'result'.\n",
    "\n",
    "PATNO_list = PD_query[\"PATNO\"].unique() #Get unique python list of PATNOs to iterate over.\n",
    "events = visit2month.keys() #Get list of Event_IDs to form combinations\n",
    "PD_followup = pd.DataFrame(columns=PD_query.columns.values.tolist()) #empty dataframe to store followup queries\n",
    "\n",
    "#Make a dataframe containing a single entry for the BL, and followup EVENT_IDs\n",
    "for PATNO_curr in PATNO_list: #iterate over all patients, check if desired EVENT_ID combination exists\n",
    "        PD_temp = pd.DataFrame(columns=PD_query.columns.values.tolist())\n",
    "        event1 = PD_query.loc[(PD_query['PATNO'] == PATNO_curr) & (PD_query['EVENT_ID'] == 'BL')] #Baseline\n",
    "        PD_temp = pd.concat([PD_temp, event1])\n",
    "        for c in events: #Iterate over followup EVENT_IDs\n",
    "            event2 = PD_query.loc[(PD_query['PATNO'] == PATNO_curr) & (PD_query['EVENT_ID'] == c)] #Followups\n",
    "            PD_temp = pd.concat([PD_temp, event2])\n",
    "            if (event1.empty == False and event2.empty == False): # follow up exists\n",
    "                PD_followup = pd.concat([PD_followup, PD_temp])\n",
    "\n",
    "#Drop duplicate entries for same Event_ID within a patient\n",
    "PD_followup = PD_followup.drop_duplicates(subset=['PATNO', 'EVENT_ID'], keep=\"first\")                \n",
    "\n",
    "#Randomly choose 18 males, 4 females at Baseline\n",
    "PD_cohort_M = PD_followup.loc[(PD_followup['SEX'] == 1.0) & \n",
    "                              (PD_followup['EVENT_ID'] == \"BL\")].sample(n=18, random_state=1)\n",
    "PD_cohort_F = PD_followup.loc[(PD_followup['SEX'] == 0.0) &\n",
    "                              (PD_followup['EVENT_ID'] == \"BL\")].sample(n=4, random_state=1)\n",
    "PD_cohort_final = pd.concat([PD_cohort_M, PD_cohort_F])\n",
    "\n",
    "#Append followup event to final cohort: first try v06, then v10\n",
    "used_PATNO_list = []\n",
    "final_PATNO_list = PD_cohort_final[\"PATNO\"].unique()\n",
    "for PATNO_curr in final_PATNO_list:\n",
    "    followup = PD_followup.loc[(PD_followup['PATNO'] == PATNO_curr) & (PD_followup['EVENT_ID'] == \"V06\")]\n",
    "    PD_cohort_final = pd.concat([PD_cohort_final, followup])\n",
    "    if followup.empty == False:\n",
    "        used_PATNO_list.append(PATNO_curr)\n",
    "    if(len(used_PATNO_list) >= 13): #Gets us closest to the 2.8yr follow-up average with range 2-4yrs\n",
    "        break    \n",
    "not_used_PATNO_list = list(set(final_PATNO_list) - set(used_PATNO_list))\n",
    "for PATNO_curr in not_used_PATNO_list: #Use some V10 visits too\n",
    "    followup = PD_followup.loc[(PD_followup['PATNO'] == PATNO_curr) & (PD_followup['EVENT_ID'] == \"V10\")]\n",
    "    PD_cohort_final = pd.concat([PD_cohort_final, followup])\n",
    "\n",
    "#display(PD_cohort_final.sort_values(['PATNO', 'EVENT_ID']))\n",
    "print(\"Number of scans in PD cohort: \" + str(len(PD_cohort_final.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scans in HC cohort: 34\n"
     ]
    }
   ],
   "source": [
    "#Control Group query\n",
    "\n",
    "# ~47 month followup, range 24-84 months within ~1yr of diagnoses (needs EVENT_ID = BL)\n",
    "visit2month = {\"V06\": 24, \"V10\": 48} # Visits with MRI scans\n",
    "\n",
    "#Initial filtering for inclusion/exclusion criteria\n",
    "HC_query = result.loc[(result['ABNORM'] == 0.0) &\n",
    "           (result['COGSTATE'] != 2.0) & \n",
    "           (result['COGSTATE'] != 3.0) &\n",
    "           (result['Depression'] != 1.0) &\n",
    "           (result['Study Date'].notnull()) &\n",
    "           (result['COHORT'] == 2.0)] #Need PRIMDIAG == 17, but seems unnecessary upon inspecting 'results'\n",
    "\n",
    "PATNO_list_HC = HC_query[\"PATNO\"].unique() #Get unique python list of PATNOs to iterate over.\n",
    "events = visit2month.keys() #Get list of Event_IDs to form combinations\n",
    "HC_followup = pd.DataFrame(columns=HC_query.columns.values.tolist()) #empty dataframe to store followup queries\n",
    "\n",
    "for PATNO_curr in PATNO_list_HC: #iterate over all controls, check if desired EVENT_ID combination exists\n",
    "        HC_temp = pd.DataFrame(columns=HC_query.columns.values.tolist())\n",
    "        event1 = HC_query.loc[(HC_query['PATNO'] == PATNO_curr) & (HC_query['EVENT_ID'] == 'BL')] #Baseline\n",
    "        HC_temp = pd.concat([HC_temp, event1])\n",
    "        for c in events: #Iterate over followup EVENT_IDs\n",
    "            event2 = HC_query.loc[(HC_query['PATNO'] == PATNO_curr) & (HC_query['EVENT_ID'] == c)] #Followups\n",
    "            HC_temp = pd.concat([HC_temp, event2])\n",
    "            if (event1.empty == False and event2.empty == False): # follow up exists\n",
    "                HC_followup = pd.concat([HC_followup, HC_temp])\n",
    "\n",
    "#Drop duplicate entries for same Event_ID within a patient\n",
    "HC_followup = HC_followup.drop_duplicates(subset=['PATNO', 'EVENT_ID'], keep=\"first\")                \n",
    "\n",
    "#Randomly choose 11 males, 6 females at Baseline - note that we are not replicating the original gender ratio!\n",
    "HC_cohort_M = HC_followup.loc[(HC_followup['SEX'] == 1.0) & \n",
    "                              (HC_followup['EVENT_ID'] == \"BL\")].sample(n=11, random_state=1)\n",
    "HC_cohort_F = HC_followup.loc[(HC_followup['SEX'] == 0.0) &\n",
    "                              (HC_followup['EVENT_ID'] == \"BL\")].sample(n=6, random_state=1)\n",
    "HC_cohort_final = pd.concat([HC_cohort_M, HC_cohort_F])\n",
    "\n",
    "#Append followup event to final cohort: first v10, then v06, to get us closer to their ~47 month followup mean\n",
    "used_PATNO_list = []\n",
    "final_PATNO_list = HC_cohort_final[\"PATNO\"].unique()\n",
    "for PATNO_curr in final_PATNO_list:\n",
    "    followup = HC_followup.loc[(HC_followup['PATNO'] == PATNO_curr) & (HC_followup['EVENT_ID'] == \"V10\")]\n",
    "    HC_cohort_final = pd.concat([HC_cohort_final, followup])\n",
    "    if followup.empty == False:\n",
    "        used_PATNO_list.append(PATNO_curr)  \n",
    "not_used_PATNO_list = list(set(final_PATNO_list) - set(used_PATNO_list))\n",
    "for PATNO_curr in not_used_PATNO_list: \n",
    "    followup = HC_followup.loc[(HC_followup['PATNO'] == PATNO_curr) & (HC_followup['EVENT_ID'] == \"V06\")]\n",
    "    HC_cohort_final = pd.concat([HC_cohort_final, followup])\n",
    "\n",
    "#display(HC_cohort_final.sort_values(['PATNO', 'EVENT_ID']))\n",
    "print(\"Number of scans in HC cohort: \" + str(len(HC_cohort_final.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the original study the authors use a Mann-Whitney U test to ensure that the difference in ages between PD subjects and controls is not significant.\n",
    "Our null hypothesis is that the distribution of PD subject ages is the same as the distribution of HC ages.\n",
    "Say we want a confidence level of 95% to reject the null hypothesis, then:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26665385103212025\n"
     ]
    }
   ],
   "source": [
    "PD_BL_age_df = PD_cohort_final.loc[(PD_cohort_final['EVENT_ID'] == \"BL\")]\n",
    "PD_BL_ages = PD_BL_age_df[\"AGE_AT_VISIT\"].tolist() #List of PD subject ages at baseline\n",
    "\n",
    "HC_BL_age_df = HC_cohort_final.loc[(HC_cohort_final['EVENT_ID'] == \"BL\")]\n",
    "HC_BL_ages = HC_BL_age_df[\"AGE_AT_VISIT\"].tolist() #List of Healthy Control ages at baseline\n",
    "\n",
    "U1, p = mannwhitneyu(PD_BL_ages, HC_BL_ages, method=\"exact\")\n",
    "print(p) #p-value for the alternative hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability of an age value being as or more extreme than the other group by chance exceeds 5%.\n",
    "Therefore the null hypothesis is not rejected, and we do not consider the difference in ages between the groups statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cohort Summary Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we do not have all of the same demographic data for our cohort as the initial study, this gives some similar statistics to their 'Table 1'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate disease duration at visit (in years, like the original study)\n",
    "\n",
    "def disease_duration_at_visit(pddxdt, StudyDate):\n",
    "    temp = StudyDate.split(\"/\")\n",
    "    d1 = datetime.strptime(pddxdt, \"%m/%Y\")\n",
    "    d2 = datetime.strptime(StudyDate, \"%m/%d/%Y\")\n",
    "    delta = d2 - d1\n",
    "    return delta.days/365.0 #days into years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PD Subject Cohort\n",
      "\n",
      "At baseline: \tmean (std)~~~~~~~~~~~~~~~~~~~~~~\n",
      "Age at Visit: \t60.57727272727272 (10.89918877794655)\n",
      "PD Duration yr: 1.1064757160647571 (1.3905080433471115)\n",
      "UPDRS III: \t22.40909090909091 (10.711182811876437)\n",
      "Hoehn & Yahr: \t1.5454545454545454 (0.5958006000151015)\n",
      "MMSE: \t\tnan (nan)\n",
      "GDS: \t\t5.0 (1.5118578920369088)\n",
      "\n",
      "At follow-up: \tmean (std)~~~~~~~~~~~~~~~~~~~~~\n",
      "Age at Visit: \t63.449999999999996 (10.628387415201756)\n",
      "UPDRS III: \t27.227272727272727 (10.364462259185371)\n",
      "Hoehn & Yahr: \t1.8181818181818181 (0.3947710169758613)\n",
      "MMSE: \t\t29.59090909090909 (0.7963662060880874)\n",
      "GDS: \t\t5.181818181818182 (1.2587357087234732)\n"
     ]
    }
   ],
   "source": [
    "# PD Subjects Cohort\n",
    "\n",
    "PD_BL_df = PD_cohort_final.loc[(PD_cohort_final['EVENT_ID'] == \"BL\")]\n",
    "PD_BL_df = PD_BL_df.drop([\"PATNO\", \"SEX\", \"COHORT\", \"PRIMDIAG\", \"COGSTATE\", \"ABNORM\", \"Depression\"], axis=1)\n",
    "PD_FU_df = PD_cohort_final.loc[(PD_cohort_final['EVENT_ID'] != \"BL\")]\n",
    "PD_FU_df = PD_FU_df.drop([\"PATNO\", \"SEX\", \"COHORT\", \"PRIMDIAG\", \"COGSTATE\", \"ABNORM\", \"Depression\"], axis=1)\n",
    "\n",
    "duration_list = []\n",
    "for index, row in PD_BL_df.iterrows():\n",
    "    dur = disease_duration_at_visit(row['PDDXDT'], row['Study Date'])\n",
    "    duration_list.append(dur)\n",
    "\n",
    "print(\"PD Subject Cohort\")\n",
    "print(\"\\nAt baseline: \\tmean (std)~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "print(\"Age at Visit: \\t\" + str(PD_BL_df[\"AGE_AT_VISIT\"].mean()) + \" (\" + str(PD_BL_df[\"AGE_AT_VISIT\"].std()) + \")\")\n",
    "print(\"PD Duration yr: \" + str(statistics.mean(duration_list)) + \" (\" + str(statistics.stdev(duration_list)) + \")\")\n",
    "print(\"UPDRS III: \\t\" + str(PD_BL_df[\"NP3TOT\"].mean()) + \" (\" + str(PD_BL_df[\"NP3TOT\"].std()) + \")\")\n",
    "print(\"Hoehn & Yahr: \\t\" + str(PD_BL_df[\"NHY\"].mean()) + \" (\" + str(PD_BL_df[\"NHY\"].std()) + \")\")\n",
    "#print(\"MoCA: \\t\" + str(PD_BL_df[\"MCATOT\"].mean()) + \" (\" + str(PD_BL_df[\"MCATOT\"].std()) + \")\")\n",
    "print(\"MMSE: \\t\\t\" + str(PD_BL_df[\"MMSETOT\"].mean()) + \" (\" + str(PD_BL_df[\"MMSETOT\"].std()) + \")\")\n",
    "print(\"GDS: \\t\\t\" + str(PD_BL_df[\"GDSTOT\"].mean()) + \" (\" + str(PD_BL_df[\"GDSTOT\"].std()) + \")\")\n",
    "print(\"\\nAt follow-up: \\tmean (std)~~~~~~~~~~~~~~~~~~~~~\")\n",
    "print(\"Age at Visit: \\t\" + str(PD_FU_df[\"AGE_AT_VISIT\"].mean()) + \" (\" + str(PD_FU_df[\"AGE_AT_VISIT\"].std()) + \")\")\n",
    "print(\"UPDRS III: \\t\" + str(PD_FU_df[\"NP3TOT\"].mean()) + \" (\" + str(PD_FU_df[\"NP3TOT\"].std()) + \")\")\n",
    "print(\"Hoehn & Yahr: \\t\" + str(PD_FU_df[\"NHY\"].mean()) + \" (\" + str(PD_FU_df[\"NHY\"].std()) + \")\")\n",
    "#print(\"MCATOT: \\t\" + str(PD_FU_df[\"MCATOT\"].mean()) + \" (\" + str(PD_FU_df[\"MCATOT\"].std()) + \")\")\n",
    "print(\"MMSE: \\t\\t\" + str(PD_FU_df[\"MMSETOT\"].mean()) + \" (\" + str(PD_FU_df[\"MMSETOT\"].std()) + \")\")\n",
    "print(\"GDS: \\t\\t\" + str(PD_FU_df[\"GDSTOT\"].mean()) + \" (\" + str(PD_FU_df[\"GDSTOT\"].std()) + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control Group Cohort\n",
      "\n",
      "At baseline: \tmean (std)~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Age at Visit: \t56.141176470588235 (12.90542806455531)\n",
      "UPDRS III: \t0.4117647058823529 (1.0036697371030325)\n",
      "Hoehn & Yahr: \t0.0 (0.0)\n",
      "MMSE: \t\tnan (nan)\n",
      "GDS: \t\t5.117647058823529 (0.6966305460192359)\n",
      "\n",
      "At follow-up: \tmean (std)~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Age at Visit: \t59.517647058823535 (12.848114418763831)\n",
      "UPDRS III: \t1.0625 (1.4361406616345072)\n",
      "Hoehn & Yahr: \t0.0 (0.0)\n",
      "MMSE: \t\t29.529411764705884 (0.6242642728467979)\n",
      "GDS: \t\t5.176470588235294 (0.6359337738364604)\n"
     ]
    }
   ],
   "source": [
    "# Control Group Cohort\n",
    "\n",
    "HC_BL_df = HC_cohort_final.loc[(HC_cohort_final['EVENT_ID'] == \"BL\")]\n",
    "HC_BL_df = HC_BL_df.drop([\"PATNO\", \"SEX\", \"COHORT\", \"PRIMDIAG\", \"COGSTATE\", \"ABNORM\", \"Depression\"], axis=1)\n",
    "HC_FU_df = HC_cohort_final.loc[(HC_cohort_final['EVENT_ID'] != \"BL\")]\n",
    "HC_FU_df = HC_FU_df.drop([\"PATNO\", \"SEX\", \"COHORT\", \"PRIMDIAG\", \"COGSTATE\", \"ABNORM\", \"Depression\"], axis=1)\n",
    "\n",
    "print(\"Control Group Cohort\")\n",
    "print(\"\\nAt baseline: \\tmean (std)~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "print(\"Age at Visit: \\t\" + str(HC_BL_df[\"AGE_AT_VISIT\"].mean()) + \" (\" + str(HC_BL_df[\"AGE_AT_VISIT\"].std()) + \")\")\n",
    "print(\"UPDRS III: \\t\" + str(HC_BL_df[\"NP3TOT\"].mean()) + \" (\" + str(HC_BL_df[\"NP3TOT\"].std()) + \")\")\n",
    "print(\"Hoehn & Yahr: \\t\" + str(HC_BL_df[\"NHY\"].mean()) + \" (\" + str(HC_BL_df[\"NHY\"].std()) + \")\")\n",
    "#print(\"MoCA: \\t\" + str(HC_BL_df[\"MCATOT\"].mean()) + \" (\" + str(HC_BL_df[\"MCATOT\"].std()) + \")\")\n",
    "print(\"MMSE: \\t\\t\" + str(HC_BL_df[\"MMSETOT\"].mean()) + \" (\" + str(HC_BL_df[\"MMSETOT\"].std()) + \")\")\n",
    "print(\"GDS: \\t\\t\" + str(HC_BL_df[\"GDSTOT\"].mean()) + \" (\" + str(HC_BL_df[\"GDSTOT\"].std()) + \")\")\n",
    "print(\"\\nAt follow-up: \\tmean (std)~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "print(\"Age at Visit: \\t\" + str(HC_FU_df[\"AGE_AT_VISIT\"].mean()) + \" (\" + str(HC_FU_df[\"AGE_AT_VISIT\"].std()) + \")\")\n",
    "print(\"UPDRS III: \\t\" + str(HC_FU_df[\"NP3TOT\"].mean()) + \" (\" + str(HC_FU_df[\"NP3TOT\"].std()) + \")\")\n",
    "print(\"Hoehn & Yahr: \\t\" + str(HC_FU_df[\"NHY\"].mean()) + \" (\" + str(HC_FU_df[\"NHY\"].std()) + \")\")\n",
    "#print(\"MoCA: \\t\" + str(HC_FU_df[\"MCATOT\"].mean()) + \" (\" + str(HC_FU_df[\"MCATOT\"].std()) + \")\")\n",
    "print(\"MMSE: \\t\\t\" + str(HC_FU_df[\"MMSETOT\"].mean()) + \" (\" + str(HC_FU_df[\"MMSETOT\"].std()) + \")\")\n",
    "print(\"GDS: \\t\\t\" + str(HC_FU_df[\"GDSTOT\"].mean()) + \" (\" + str(HC_FU_df[\"GDSTOT\"].std()) + \")\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test2",
   "language": "python",
   "name": "test2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
